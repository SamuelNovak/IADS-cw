\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{tikz}
\usepackage{hyperref}

\newcommand{\todo}[1]{\textcolor{red}{$\star$~TODO: \textbf{#1}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\randint}{\operatorname{RANDINT}}
% \newcommand{\argmin}[1]{\operatorname{argmin}\limits_{#1}}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\qed}{\begin{flushright}$\bowtie$\end{flushright}}

\newcommand{\bb}[1]{\textbf{#1}}
\newcommand{\uu}[1]{\underline{#1}}
\newcommand{\ii}[1]{\textit{#1}}

\newenvironment{pyc}{\begin{lstlisting}[language=Python]}{\end{lstlisting}}
\newcommand{\py}[1]{\lstinline[language=Python]{#1}}

\newcommand{\vertex}[1]{\filldraw [black] (#1) circle (1.5mm)}

\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{2}
% \renewcommand{\thealgocf}{}


\title{IADS Coursework 3}
\author{Samo Nov\'ak (s1865783)}
\date{March 2020}

\begin{document}

\maketitle

\section{Algorithm: Nearest Neighbour Insertion}

\todo{Name? Call it \bb{expansion}?}

We draw inspiration for this algorithm from the outline of Nearest Insertion
(and other TSP heuristics) by Nilsson\cite{nilsson}. We chose this particular
algorithm because of its elegance -- it follows a very simple principle:
start with some trivial circuit of minimum weight and then find the most suitable
nodes to add to it, until all nodes are used. The pseudocode for this algorithm is
presented below, as is some more discussion and visual explanation. In the program
submitted, this is \py{Graph.NearestExpand()}.
\\

\begin{algorithm}[H]
  \KwIn{an undirected complete graph $G=(V,E)$, where $|V| = n$}
  \KwIn{a weight function $w:V\times V \to \mathbb{R}^{+}$,
    note: $\forall v\in V \ldotp w(v,v) = 0$}
  \KwResult{a permutation $\pi$ (represented as list) of
    all vertices representing a circuit (the path the travelling salesperson will take)}

  Initialize: $\pi \gets [i,j]$, where $(i,j)=\argmin_{(i,j)\in E} w(i,j)$ \nllabel{init-pi}
  \tcc*{$\Theta(n^2)$}
  
  Initialize: $U = \{ x\in V | x \notin \pi \}$ \nllabel{init-unused}
  \tcc*{$\Theta(n)$}
  \While{$U \ne \varnothing$  \tcc*{cycle will run $n-2 = \Theta(n)$ times}}{
    $(i, u)\gets \argmin_{(i,v):\;i\in\{0,...,|\pi|-1\},\;v\in U}
    \left\{w\left(\pi[i], v\right)\right\}$ \nllabel{argmin-iu}
    \tcc*{$\Theta\left( n \right)$}
    
    $d_{-} \gets w\left( u, \pi\left[(i-1) \mod |\pi|\right] \right)$
    \nllabel{dminus} \tcc*{$\Theta(1)$}
    
    $d_{+} \gets w\left( u, \pi\left[(i+1) \mod |\pi|\right] \right)$
    \nllabel{dplus} \tcc*{$\Theta(1)$}
    
    \eIf{$d_{-} < d_{+}$ \nllabel{choose-insertion-point} \tcc*{$\Theta(1)$}}{
      Insert $u$ into $\pi$ at position $i$
      \tcc*{$\Theta(n)$}
    }{
      Insert $u$ into $\pi$ after position $i$, so at
      position $(i+1)\mod|\pi|$
      \tcc*{$\Theta(n)$}
    }
    Remove $u$ from $U$. \tcc*{$O(|U|)$ (impl. dep.)}
  }
  \KwRet{$\pi$}\;
  \caption{Nearest Insert}
\end{algorithm}

On line~\ref*{init-pi}, we initialize the permutation $\pi$ to a list of two nodes
$i,j$, such that their distance $w(i,j)$ in the graph is minimal. We also intialize
a set $U$ of nodes \ii{yet unused} in $\pi$ (line~\ref*{init-unused}).

We shall repeat the following steps \bb{while} $U$ is not empty, meaning $\pi$
does not contain all the nodes. First we need to find the nearest neighbour
(an unused node) $u$ to some node contained in $\pi$ (at index $i$). We do this
by looking for a pair where first element is the index in $\pi$ and the second is
an unused node, such that the nodes $u$ and $\pi[i]$ have minimal distance
(line~\ref*{argmin-iu}).

Next, we need to decide where to place the new node $u$. We know, that its distance to
$\pi[i]$ is minimal, but there are two ways to insert it into $\pi$: before $\pi[i]$
or after it. Therefore, we need to compare the distances to the predecessor and
successor of $\pi[i]$ in the permutation. We use $\pi[(i\pm 1)\mod|\pi|]$
(lines~\ref*{dminus},~\ref*{dplus}), because the salesperson's walk is a cycle,
so the first and last node in $\pi$ are connected as well. We then choose the lower
distance, because we want to minimize the weight of the permutation overall.
(\bb{if} statement starting at line~\ref*{choose-insertion-point})

After inserting $u$ at the appropriate position, we remove it from $U$ -- we wouldn't want
to insert the same node multiple times. We also like our algorithms to terminate.

The running time of this algorithm is $\Theta(n^2)$, where $n=|V|$. This comes
from the fact that the most significant contributions are done by the $\Theta(n^2)$
terms. Insertions take $\Theta(n)$ time, due to array representation of the list $\pi$.
If we implement $U$ also as a list (as is done in the program), removal from it
will be $\Theta(|U|)$ (this will start of as $\Theta(n)$ and decrease). The running
time of lines~\ref*{init-pi}, \ref*{init-unused}, \ref*{argmin-iu} will be elaborated
in the Appendix~\ref{appendix:runtime-ni}, in the interest of preserving clarity
in this section.

Below is a simple visualisation of the described algorithm. We have used a 2-D
Euclidean graph for the visualisation, because it will be easy to see distances
intuitively.
\\

\begin{figure}[h]
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw[dashed] (3,1) -- (4,1);

    \node (3,-1) {(a)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1);
    \draw[dashed] (4,1) -- (4,3);
    \draw[dotted] (4,3) .. controls (3,2) and (3,2) .. (3,1);
    \draw[dotted] (4,3) .. controls (3.5,1.5) and (3.5,1.5) .. (3,1);

    \node (3,-1) {(b)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1) -- (4,3) -- (3,1);
    \draw[dashed] (4,3) -- (3,5);
    \draw[dotted] (3,5) -- (3,1);
    \draw[dotted] (3,5) -- (4,1);
    
    \node (3,-1) {(c)};
  \end{tikzpicture}
  \\
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1) -- (4,3) -- (3,5) -- (3,1);
    \draw[dashed] (1,3) -- (3,1);
    \draw[dotted] (1,3) -- (3,5);
    \draw[dotted] (1,3) -- (4,1);
    
    \node (3,-1) {(d)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (1,3) -- (3,1) -- (4,1) -- (4,3) -- (3,5) -- (1,3);
    
    \node (3,-1) {(e)};
  \end{tikzpicture}
\end{figure}

In these diagrams, \ii{full} lines represent the current permutation $\pi$,
\ii{dashed}~lines represent the edge that will be definitely added into $\pi$ next
(line \ref*{init-pi} in initialization, line \ref*{argmin-iu} in loop),
and \ii{dotted}~lines represent the other two nodes that are being condidered
(lines \ref*{dminus}, \ref*{dplus}).

\todo{Elaborate? Treba vobec?}

\section{Experiments}

In this part, we were to generate (or write a generator for) many different
test cases and quantitatively measure how each heuristic (Swap, 2-Opt,
Greedy, \todo{own}) performs.

\subsection{Test generation}

Firstly, let us summarize the assumptions and setting of the problem:
\begin{itemize}
\item We have an \uu{undirected}, \uu{complete} graph $G=(V,E)$ where $|V|=n$.
\item We have a weight function $w:V\times V\to\R^{+}$, such that
  $\forall i,j\in V \ldotp w(i,j) = w(j,i)$, which will be represented as
  a \uu{symmetric} matrix \py{Graph.dists[i][j]}\,$= w(i,j)$).
  We assume $\forall i\in V\ldotp w(i,i)=0$.
\item We have three cases of our problem: \uu{general} TSP
  (no other constraints), \uu{metric} TSP ($w$ is a metric, so
  $\forall u,v,x\in V\ldotp w(u,v)\le w(u,x) + w(x,v)$), and
  \uu{Euclidean} TSP (the graph is embedded in a plane, this is also metric).
\end{itemize}

The test cases could be generated as completely random graphs. For small graphs
(\todo{how big?}), it is then feasible to compute the best path, so that we can
compare it to the results from the tested heuristics. However, for larger graphs,
it will be more useful to generate a graph with some pre-planned best path.

\subsubsection{Small random graphs}

Generating these will be simple: we shall populate the matrix
\py{Graph.dists} with random positive integers. Then we will
compute the best TSP path.

In the \uu{Euclidean} case, we will instead generate randomly positioned
cities in a plane.

For a general \uu{metric} case, we will generate the cities randomly embedded
in a plane, same as in the Euclidean case. However, we will use
the \uu{taxicab} metric (also called the \uu{Manhattan} metric), which measures
the distance along the axes individually and sums them. In the case of discrete
positions (which we will use):
\begin{align*}
  & w_M: \mathbb{N}^d \times \mathbb{N}^d \to \mathbb{N} \\
  & w_M\left(\left<u_1,...,u_d\right>, \left<v_1,...,v_d\right>\right) = \sum_{i=1}^d \left|u_i - v_i\right|
\end{align*}
where $d$ is the number of dimensions of the space (we may use arbitrary
$d\in\mathbb{Z}^{+}$).

Since all these graphs will be small, we can get the optimal TSP solution by
simply trying out all the permutations.

\subsubsection{Larger graphs}

A good way to intentionally generate an optimal path in a (general) graph is to create
a cycle with small weights in it and then assign larger values to all the other
edges. So:
\begin{align*}\forall i\in\{0,...,n-2\}\ldotp w(i,i+1) & =\randint(1,5)\\
  \forall i,j\in{0,...,n-1}\ldotp i\ne j \wedge j\ne i+1 \ldotp
  w(i,j) & = \randint(6,10) \\
\end{align*}
The random number boundaries here are somewhat arbitrary, we just need to make
sure that the cycle has smaller values. In the code, the threshold between these
(here 5) is the argument \py{low_cycle_threshold}.

Once we have this matrix, we swap the vertices around, so that the initial
permutation $[0,1,...,n-1]$ won't immediately be the solution. We do this by
generating a graph that is \uu{isomorphic} to the original one. For graph isomorphism,
we need a \ii{bijection} between the vertices of the old one and the new one. We
generate a permutation $p:V\to V$ to be this bijection and then create a corresponding
new weight function $w^\star:V\times V \to \mathbb{R}^{+}$:
\[ \forall i,j\in V \ldotp
  w^\star\left( p(i), p(j) \right)
  = w(i,j) \]

For metric (and Euclidean, which are also metric) graphs, we generate a circle w.r.t.
the particular metric we are using, and then reorder the nodes similarly.

\subsection{Results}

\begin{tabular}{|c c|r r r r r|}
  \hline Type & $n$ & \shortstack{ Swap \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ TwoOpt \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ Swap, TwoOpt \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ Greedy \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ NearestInsert \\ vs. $W_0$ \\ vs. $W_i$ } \\ 
  \hline\hline
  G & 5 & \shortstack{ 1.003 \\ 0.748 } & \shortstack{ 1.004 \\ 0.748 } & \shortstack{ 1.003 \\ 0.748 } & \shortstack{ 1.053 \\ 0.784 } & \shortstack{ 1.158 \\ 0.856 } \\ 
  \hline
  G & 7 & \shortstack{ 1.23 \\ 0.703 } & \shortstack{ 1.027 \\ 0.596 } & \shortstack{ 1.026 \\ 0.595 } & \shortstack{ 1.113 \\ 0.648 } & \shortstack{ 1.261 \\ 0.726 } \\ 
  \hline
  G & 10 & \shortstack{ 1.545 \\ 0.775 } & \shortstack{ 1.011 \\ 0.513 } & \shortstack{ 1.014 \\ 0.515 } & \shortstack{ 1.074 \\ 0.545 } & \shortstack{ 1.361 \\ 0.685 } \\ 
  \hline
  G & 20 & \shortstack{ 1.929 \\ 0.845 } & \shortstack{ 1.036 \\ 0.458 } & \shortstack{ 1.036 \\ 0.458 } & \shortstack{ 1.058 \\ 0.467 } & \shortstack{ 1.498 \\ 0.659 } \\ 
  \hline
  G & 50 & \shortstack{ 2.226 \\ 0.876 } & \shortstack{ 1.066 \\ 0.422 } & \shortstack{ 1.064 \\ 0.421 } & \shortstack{ 1.04 \\ 0.411 } & \shortstack{ 1.612 \\ 0.636 } \\ 
  \hline\hline
  M & 5 & \shortstack{ 1.001 \\ 0.835 } & \shortstack{ 1.001 \\ 0.835 } & \shortstack{ 1.001 \\ 0.835 } & \shortstack{ 1.046 \\ 0.873 } & \shortstack{ 1.052 \\ 0.874 } \\ 
  \hline
  M & 7 & \shortstack{ 1.164 \\ 0.762 } & \shortstack{ 1.008 \\ 0.665 } & \shortstack{ 1.008 \\ 0.664 } & \shortstack{ 1.087 \\ 0.717 } & \shortstack{ 1.146 \\ 0.753 } \\ 
  \hline
  M & 10 & \shortstack{ 1.606 \\ 0.796 } & \shortstack{ 1.018 \\ 0.507 } & \shortstack{ 1.091 \\ 0.543 } & \shortstack{ 1.174 \\ 0.584 } & \shortstack{ 1.556 \\ 0.774 } \\ 
  \hline
  M & 20 & \shortstack{ 2.679 \\ 0.774 } & \shortstack{ 1.012 \\ 0.293 } & \shortstack{ 1.033 \\ 0.299 } & \shortstack{ 1.342 \\ 0.39 } & \shortstack{ 1.725 \\ 0.5 } \\ 
  \hline
  M & 50 & \shortstack{ 6.556 \\ 0.755 } & \shortstack{ 1.005 \\ 0.116 } & \shortstack{ 1.017 \\ 0.117 } & \shortstack{ 1.206 \\ 0.139 } & \shortstack{ 1.925 \\ 0.222 } \\ 
  \hline\hline
  E & 5 & \shortstack{ 1.001 \\ 0.827 } & \shortstack{ 1.001 \\ 0.826 } & \shortstack{ 1.001 \\ 0.827 } & \shortstack{ 1.047 \\ 0.865 } & \shortstack{ 1.066 \\ 0.881 } \\ 
  \hline
  E & 7 & \shortstack{ 1.132 \\ 0.801 } & \shortstack{ 1.002 \\ 0.714 } & \shortstack{ 1.004 \\ 0.715 } & \shortstack{ 1.07 \\ 0.763 } & \shortstack{ 1.16 \\ 0.826 } \\ 
  \hline
  E & 10 & \shortstack{ 1.69 \\ 0.779 } & \shortstack{ 1.0 \\ 0.464 } & \shortstack{ 1.0 \\ 0.464 } & \shortstack{ 1.0 \\ 0.464 } & \shortstack{ 1.623 \\ 0.753 } \\ 
  \hline
  E & 20 & \shortstack{ 2.933 \\ 0.75 } & \shortstack{ 1.0 \\ 0.257 } & \shortstack{ 1.0 \\ 0.257 } & \shortstack{ 1.0 \\ 0.257 } & \shortstack{ 1.794 \\ 0.461 } \\ 
  \hline
  E & 50 & \shortstack{ 7.139 \\ 0.757 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.928 \\ 0.205 } \\ 
  \hline
\end{tabular}

\appendix
\section*{APPENDIX}
% \renewcommand{\thesection}{$\Omega$\roman{section}}
\renewcommand{\thesection}{\roman{section}}
\section{Running time of Nearest Insert}
\label{appendix:runtime-ni}

This section concerns the running time of algorithm \todo{name}.

\subsection{$\argmin$ on line \ref*{init-pi}}

By the concrete properties of our weight functions $w:V\times V\to\mathbb{R}^{+}$
(symmetry and $\forall u\in V\ldotp w(u,u)=0$):
\[ \argmin_{(i,j)\in E} w(i,j) = \argmin_{\substack{(i,j)\in V\times V\\j<i}} w(i,j) \]
So the running time, which depends on the number of lookups (where a lookup of $w(i,j)$
is $\Theta(1)$, because we represent $w$ as a matrix):
\[ \sum_{i=0}^{n-1} \sum_{j=0}^{i-1} \Theta(1) = \Theta(1) \sum_{i=0}^{n-1} i
  = \Theta(1) \cdot \frac{(n-1)(n-1+1)}{2} = \Theta(n^2) \]
\qed

\subsection{Unused nodes set on line \ref*{init-unused}}

Here we iterate over $n$ nodes and check their membership in a list of 2. This means
running time $\Theta(2n) = \Theta(n)$. \qed

\subsection{$\argmin$ on line \ref*{argmin-iu}}

In each iteration of the \bb{while} loop let $k$ be the number of iteration,
starting at $k=0$ just after initialization. Let $\pi_k$ and $U_k$ be the permutation,
and unused nodes set, respectively, after $k^{\mathrm{th}}$ iteration.
Then $|\pi_k| = |\pi_0|+k = k+2$, since at every iteration we
add one node to $\pi$, and we start off with two nodes ($|\pi_0|=2$). In all iterations,
$\pi_k\cup U_k=V$ and $\pi_k\cap U_k=\varnothing$, so $|U_k|=n-|\pi_k|$. A lookup takes
$\Theta(1)$ time. Then running time of $\argmin_{(i,v):\;i\in\{0,...,|\pi|-1\},\;v\in U}
\left\{w\left(\pi[i], v\right)\right\}$ is, in every iteration:

\begin{align*}
  \Theta(|\pi_k||U_k|) & = \Theta\left[ (k+2)(n-(k+2)) \right] \\
                       & = \Theta\left[ (k+2)(n-k-2) \right] \\
                       & = \Theta(kn - k^2 - 2k + 2n - 2k - 4) \\
                       & = \Theta(2n + kn - k^2 - 4k - 4) \\
                       & = \Theta(n + kn - k^2 - k)
\end{align*}

Our $k$ will range over $\{0,...,n-2\}$. If $k=0$ (\bb{base case}):
\begin{align*}
  \Theta(|\pi_0||U_0|) & = \Theta(n + kn - k^2 - k) \\
                       & = \Theta(n + 0 - 0 - 0)
\end{align*}
\begin{equation}
  \label{base-case}
  \therefore \Theta(|\pi_0||U_0|) = \Theta(n)
\end{equation}

Now show that if for arbirary $k\in\{0,...,n-3\}$ it is true thaty
$\Theta(|\pi_k||U_k|) = \Theta(n + kn - k^2 - k) = \Theta(n)$ then for
$k+1$ it holds too.

\begin{align*}
  \Theta(|\pi_{k+1}||U_{k+1}|) & = \Theta(n + (k+1)n - (k+1)^2 - (k+1)) \\
                               & = \Theta(n + kn + n - k^2 - 2k - 1 -k -1) \\
                               & = \Theta(2n + kn - k^2 - 3k - 2) \\
                               & = \Theta(n + kn - k^2 - k) \\
                               & = \Theta(|\pi_k||U_k|) \\
\end{align*}
And now by induction from (\ref*{base-case}), we get that:
\[ \therefore \forall k\in\{0,...,n-2\}\ldotp
  \Theta(|\pi_k||U_k|) = \Theta(n)\]
\qed


\bibliographystyle{abbrv}
\begin{thebibliography}{9}
\bibitem{nilsson}
  Christian Nilsson,
  \textit{Heuristics for the Traveling Salesman Problem},
  Link\"oping University,
  2003.
  Accessible online [27-03-2020]: \url{https://pdfs.semanticscholar.org/7b80/bfc1c5dd4e10ec807c6f56d0f31f8bf86bc6.pdf}
\end{thebibliography}

\end{document}
