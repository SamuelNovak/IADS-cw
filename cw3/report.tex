\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{tikz}
\usepackage{hyperref}

\newcommand{\todo}[1]{\textcolor{red}{$\star$~TODO: \textbf{#1}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\randint}{\operatorname{RANDINT}}
% \newcommand{\argmin}[1]{\operatorname{argmin}\limits_{#1}}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\qed}{\begin{flushright}$\bowtie$\end{flushright}}

\newcommand{\bb}[1]{\textbf{#1}}
\newcommand{\uu}[1]{\underline{#1}}
\newcommand{\ii}[1]{\textit{#1}}

\newenvironment{pyc}{\begin{lstlisting}[language=Python]}{\end{lstlisting}}
\newcommand{\py}[1]{\lstinline[language=Python]{#1}}

\newcommand{\vertex}[1]{\filldraw [black] (#1) circle (1.5mm)}

\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{2}
% \renewcommand{\thealgocf}{}


\title{IADS Coursework 3}
\author{Samo Nov\'ak (s1865783)}
\date{March 2020}

\begin{document}

\begin{tabular}{p{0.2\textwidth} p{0.4\textwidth} p{0.2\textwidth}}
  \shortstack{Samo Nov\'ak \\ (s1865783)}
  & {\LARGE IADS Coursework 3}
  & March 2020
\end{tabular}

\section{Algorithm: Nearest Neighbour Insertion}

We draw inspiration for this algorithm from the outline of Nearest Insertion
(and other TSP heuristics) by Nilsson\cite{nilsson}. We chose this particular
algorithm because of its elegance -- it follows a very simple principle:
start with some trivial circuit of minimum weight and then find the most suitable
nodes to add to it, until all nodes are used. The pseudocode for this algorithm is
presented below, as is some more discussion and visual explanation. In the program
submitted, this is \py{Graph.NearestExpand()}.
\\

\begin{algorithm}[H]
  \KwIn{an undirected complete graph $G=(V,E)$, where $|V| = n$}
  \KwIn{a weight function $w:V\times V \to \mathbb{R}^{+}$,
    note: $\forall v\in V \ldotp w(v,v) = 0$}
  \KwResult{a permutation $\pi$ (represented as list) of
    all vertices representing a circuit (the path the travelling salesperson will take)}

  Initialize: $\pi \gets [i,j]$, where $(i,j)=\argmin_{(i,j)\in E} w(i,j)$ \nllabel{init-pi}
  \tcc*{$\Theta(n^2)$}
  
  Initialize: $U = \{ x\in V | x \notin \pi \}$ \nllabel{init-unused}
  \tcc*{$\Theta(n)$}
  \While{$U \ne \varnothing$  \tcc*{cycle will run $n-2 = \Theta(n)$ times}}{
    $(i, u)\gets \argmin_{(i,v):\;i\in\{0,...,|\pi|-1\},\;v\in U}
    \left\{w\left(\pi[i], v\right)\right\}$ \nllabel{argmin-iu}
    \tcc*{$\Theta\left( n \right)$}
    
    $d_{-} \gets w\left( u, \pi\left[(i-1) \mod |\pi|\right] \right)$
    \nllabel{dminus} \tcc*{$\Theta(1)$}
    
    $d_{+} \gets w\left( u, \pi\left[(i+1) \mod |\pi|\right] \right)$
    \nllabel{dplus} \tcc*{$\Theta(1)$}
    
    \eIf{$d_{-} < d_{+}$ \nllabel{choose-insertion-point} \tcc*{$\Theta(1)$}}{
      Insert $u$ into $\pi$ at position $i$
      \tcc*{$\Theta(n)$}
    }{
      Insert $u$ into $\pi$ after position $i$, so at
      position $(i+1)\mod|\pi|$
      \tcc*{$\Theta(n)$}
    }
    Remove $u$ from $U$. \tcc*{$\Theta(|U|)$}
  }
  \KwRet{$\pi$}\;
  \caption{Nearest Insert}
\end{algorithm}

First, we initialize the permutation $\pi$ to a list of two nodes with minimum distance
(line~\ref*{init-pi}). We also initialize a set $U$ of nodes \ii{yet unused} in $\pi$
(line~\ref*{init-unused}).

Then we will repeat the following \bb{while} we still have unused nodes ($U$ is nonempty).
We first find an unused node ($u$) that is a nearest neighbour to one of the nodes
in $\pi$ (at index $i$) -- so that $w(\pi[i], u)$ is minimal (line~\ref*{argmin-iu}).

Next, we need to decide where to insert the new node $u$. We know that its distance to
$\pi[i]$ is minimal, but we need to decide whether to insert it before $\pi[i]$ or
after it. Because the permutation is a cycle, we can use $\pi[(i\pm 1)\mod |\pi|]$,
and then we pick the one that has lower distance to $u$, because we are trying to
build a cycle of minimum distance (lines~\ref*{dminus},~\ref*{dplus} and the \bb{if}
starting at line~\ref*{choose-insertion-point}).

After inserting $u$ at the appropriate position, we remove it from $U$ -- we wouldn't want
to insert the same node multiple times.

The running time of this algorithm is $\Theta(n^2)$, where $n=|V|$. This is because
the most significant contributions are done by the $\Theta(n^2)$ terms. Insertions
take $\Theta(n)$ time, due to array representation of the list $\pi$.
If we implement $U$ also as a list (as is done in the program), removal from it
will be $\Theta(|U|)$ (this will start off as $\Theta(n)$ and decrease). The running
time of lines~\ref*{init-pi}, \ref*{init-unused}, \ref*{argmin-iu} will be elaborated
in the Appendix~\ref{appendix:runtime-ni}, in the interest of preserving clarity
in this section.

Below is a simple visualisation of the described algorithm. We have used a 2-D
Euclidean graph for the visualisation, because it will be easy to see distances
intuitively.
\\

\begin{figure}[h]
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw[dashed] (3,1) -- (4,1);

    \node (3,-1) {(0)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1);
    \draw[dashed] (4,1) -- (4,3);
    \draw[dotted] (4,3) .. controls (3,2) and (3,2) .. (3,1);
    \draw[dotted] (4,3) .. controls (3.5,1.5) and (3.5,1.5) .. (3,1);

    \node (3,-1) {(1)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1) -- (4,3) -- (3,1);
    \draw[dashed] (4,3) -- (3,5);
    \draw[dotted] (3,5) -- (3,1);
    \draw[dotted] (3,5) -- (4,1);
    
    \node (3,-1) {(2)};
  \end{tikzpicture}
  \\
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (3,1) -- (4,1) -- (4,3) -- (3,5) -- (3,1);
    \draw[dashed] (1,3) -- (3,1);
    \draw[dotted] (1,3) -- (3,5);
    \draw[dotted] (1,3) -- (4,1);
    
    \node (3,-1) {(3)};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[scale=.5,auto=left]
    \vertex{1,3};
    \vertex{3,1};
    \vertex{3,5};
    \vertex{4,1};
    \vertex{4,3};

    \draw (1,3) -- (3,1) -- (4,1) -- (4,3) -- (3,5) -- (1,3);
    
    \node (3,-1) {(4)};
  \end{tikzpicture}
\end{figure}

In these diagrams, \ii{full} lines represent the current permutation $\pi$,
\ii{dashed}~lines represent the edge that will be definitely added into $\pi$ next
(line~\ref*{init-pi} in initialization, line~\ref*{argmin-iu} in the \bb{while} loop),
and \ii{dotted}~lines represent the other two nodes that are being condidered to close
the cycle (lines~\ref*{dminus},~\ref*{dplus}).

\section{Experiments}

In this part, we created generators for different types and sizes of graphs, and then
comparatively tested six heuristics: \ii{Swap}, \ii{2-Opt}, \ii{Swap} followed by
\ii{2-Opt}, \ii{Greedy} and \ii{Nearest Insert}.

We have three cases of our problem: \uu{general} TSP (no other constraints),
\uu{metric} TSP ($w$ is a metric, so
$\forall u,v,x\in V\ldotp w(u,v)\le w(u,x) + w(x,v)$), and \uu{Euclidean} TSP
(the graph is embedded in a plane, this is also metric).

% \subsection{Test generation}

% Firstly, let us summarize the assumptions and setting of the problem:
% \begin{itemize}
% \item We have an \uu{undirected}, \uu{complete} graph $G=(V,E)$ where $|V|=n$.
% \item We have a weight function $w:V\times V\to\R^{+}$, such that
%   $\forall i,j\in V \ldotp w(i,j) = w(j,i)$, which will be represented as
%   a \uu{symmetric} matrix \py{Graph.dists[i][j]}\,$= w(i,j)$).
%   We assume $\forall i\in V\ldotp w(i,i)=0$.
% \item 
% \end{itemize}

The test cases could be generated as completely random graphs. For small graphs
(here $n\le 7$), it is then feasible to compute the best path, so that we can
compare it to the results from the tested heuristics. However, for larger graphs,
it will be more useful to generate a graph with some pre-planned best path.

\subsection{Small random graphs}

Generating these will be simple: we will populate the matrix
\py{Graph.dists} with random positive integers. Then we will
brute-force the best TSP path.

In the \uu{Euclidean} case, we will instead generate randomly positioned
cities in a plane.

For a general \uu{metric} case, we will generate the cities randomly embedded
in a plane, same as in the Euclidean case. However, we will use
the \uu{taxicab} metric (also called the \uu{Manhattan} metric), which measures
the distance along the axes individually and sums them. In the case of discrete
positions (which we will use):
\begin{align*}
  & w_M: \mathbb{N}^d \times \mathbb{N}^d \to \mathbb{N} \\
  & w_M\left(\left<u_1,...,u_d\right>, \left<v_1,...,v_d\right>\right) = \sum_{i=1}^d \left|u_i - v_i\right|
\end{align*}
where $d$ is the number of dimensions of the space (we may use arbitrary
$d\in\mathbb{Z}^{+}$).

Since all these graphs will be small, we can get the optimal TSP solution by
simply trying out all the permutations.

\subsection{Larger graphs}

A good way to intentionally generate an optimal path in a (general) graph is to create
a cycle with small weights in it and then assign larger values to all the other
edges. So:
\begin{align*}\forall i\in\{0,...,n-2\}\ldotp w(i,i+1) & =\randint(1,5)\\
  \forall i,j\in{0,...,n-1}\ldotp i< j \wedge j\ne i+1 \ldotp
  w(i,j) & = \randint(6,10) \\
\end{align*}
The random number boundaries here are somewhat arbitrary, we just need to make
sure that the cycle has smaller values. In the code, the threshold between these
(here 5) is the argument \py{low_cycle_threshold}.

Once we have this matrix, we swap the vertices around, so that the initial
permutation $[0,1,...,n-1]$ won't immediately be the solution. We do this by
generating a graph that is \uu{isomorphic} to the original one, i.e. $\exists$
\ii{bijection} between the vertices of the old one and the new one that preserves
the graph structure. We
generate a permutation $p:V\to V$ to be this bijection and then create a corresponding
new weight function $w^\star:V\times V \to \mathbb{R}^{+}$:
\[ \forall i,j\in V \ldotp
  w^\star\left( p(i), p(j) \right)
x  = w(i,j) \]

For metric (and Euclidean) graphs, we generate a circle w.r.t.
the particular metric we are using, and then reorder the nodes similarly.

\subsection{Results}

We have tested multiple graphs of different types and sizes. In the following table,
$W_0$ is the optimal path weight (total distance), and $W_i$ is the weight of the initial
permutation $\forall i\in \{ 0,...,n-1 \} \ldotp \pi(i)=i$. Types of graphs are
\bb{G} for general, \bb{M} for metric, and \bb{E} for Euclidean. All measurements are
averaged over 100 random graphs of the specified type and size.

{\small
\begin{tabular}{|c c|r r r r r|}
  \hline Type & $n$ & \shortstack{ Swap \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ 2-Opt \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ Swap, 2-Opt \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ Greedy \\ vs. $W_0$ \\ vs. $W_i$ } & \shortstack{ NearestInsert \\ vs. $W_0$ \\ vs. $W_i$ } \\
  \hline\hline
  G & 5 & \shortstack{ 1.002 \\ 0.728 } & \shortstack{ 1.003 \\ 0.729 } & \shortstack{ 1.002 \\ 0.728 } & \shortstack{ 1.053 \\ 0.766 } & \shortstack{ 1.133 \\ 0.819 } \\ 
  \hline
  G & 7 & \shortstack{ 1.21 \\ 0.69 } & \shortstack{ 1.028 \\ 0.598 } & \shortstack{ 1.03 \\ 0.598 } & \shortstack{ 1.157 \\ 0.671 } & \shortstack{ 1.246 \\ 0.718 } \\ 
  \hline
  G & 10 & \shortstack{ 1.593 \\ 0.802 } & \shortstack{ 1.018 \\ 0.521 } & \shortstack{ 1.019 \\ 0.522 } & \shortstack{ 1.05 \\ 0.536 } & \shortstack{ 1.433 \\ 0.726 } \\ 
  \hline
  G & 20 & \shortstack{ 1.969 \\ 0.835 } & \shortstack{ 1.044 \\ 0.447 } & \shortstack{ 1.049 \\ 0.449 } & \shortstack{ 1.061 \\ 0.453 } & \shortstack{ 1.543 \\ 0.656 } \\ 
  \hline
  G & 50 & \shortstack{ 2.186 \\ 0.868 } & \shortstack{ 1.063 \\ 0.425 } & \shortstack{ 1.062 \\ 0.424 } & \shortstack{ 1.038 \\ 0.415 } & \shortstack{ 1.601 \\ 0.637 } \\ 
  \hline
  G & 100 & \shortstack{ 2.288 \\ 0.879 } & \shortstack{ 1.071 \\ 0.412 } & \shortstack{ 1.065 \\ 0.41 } & \shortstack{ 1.027 \\ 0.395 } & \shortstack{ 1.636 \\ 0.629 } \\ 
  \hline
  G & 200 & \shortstack{ 2.343 \\ 0.89 } & \shortstack{ 1.066 \\ 0.406 } & \shortstack{ 1.066 \\ 0.405 } & \shortstack{ 1.015 \\ 0.386 } & \shortstack{ 1.647 \\ 0.626 } \\ 
  \hline\hline
  M & 5 & \shortstack{ 1.001 \\ 0.831 } & \shortstack{ 1.001 \\ 0.831 } & \shortstack{ 1.001 \\ 0.831 } & \shortstack{ 1.039 \\ 0.862 } & \shortstack{ 1.048 \\ 0.867 } \\ 
  \hline
  M & 7 & \shortstack{ 1.16 \\ 0.779 } & \shortstack{ 1.012 \\ 0.687 } & \shortstack{ 1.01 \\ 0.685 } & \shortstack{ 1.068 \\ 0.726 } & \shortstack{ 1.17 \\ 0.791 } \\ 
  \hline
  M & 10 & \shortstack{ 1.604 \\ 0.792 } & \shortstack{ 1.051 \\ 0.522 } & \shortstack{ 1.072 \\ 0.533 } & \shortstack{ 1.199 \\ 0.595 } & \shortstack{ 1.556 \\ 0.771 } \\ 
  \hline
  M & 20 & \shortstack{ 2.742 \\ 0.77 } & \shortstack{ 1.014 \\ 0.286 } & \shortstack{ 1.032 \\ 0.29 } & \shortstack{ 1.369 \\ 0.384 } & \shortstack{ 1.723 \\ 0.485 } \\ 
  \hline
  M & 50 & \shortstack{ 6.527 \\ 0.747 } & \shortstack{ 1.011 \\ 0.116 } & \shortstack{ 1.032 \\ 0.118 } & \shortstack{ 1.291 \\ 0.148 } & \shortstack{ 1.926 \\ 0.221 } \\ 
  \hline
  M & 100 & \shortstack{ 12.764 \\ 0.76 } & \shortstack{ 1.014 \\ 0.06 } & \shortstack{ 1.018 \\ 0.061 } & \shortstack{ 1.421 \\ 0.085 } & \shortstack{ 1.943 \\ 0.116 } \\ 
  \hline
  M & 200 & \shortstack{ 25.35 \\ 0.755 } & \shortstack{ 1.006 \\ 0.03 } & \shortstack{ 1.007 \\ 0.03 } & \shortstack{ 1.424 \\ 0.042 } & \shortstack{ 1.963 \\ 0.058 } \\ 
  \hline\hline
  E & 5 & \shortstack{ 1.001 \\ 0.846 } & \shortstack{ 1.001 \\ 0.846 } & \shortstack{ 1.001 \\ 0.846 } & \shortstack{ 1.049 \\ 0.886 } & \shortstack{ 1.066 \\ 0.898 } \\ 
  \hline
  E & 7 & \shortstack{ 1.176 \\ 0.796 } & \shortstack{ 1.002 \\ 0.683 } & \shortstack{ 1.003 \\ 0.684 } & \shortstack{ 1.062 \\ 0.726 } & \shortstack{ 1.153 \\ 0.785 } \\ 
  \hline
  E & 10 & \shortstack{ 1.697 \\ 0.789 } & \shortstack{ 1.0 \\ 0.468 } & \shortstack{ 1.0 \\ 0.468 } & \shortstack{ 1.0 \\ 0.468 } & \shortstack{ 1.623 \\ 0.759 } \\ 
  \hline
  E & 20 & \shortstack{ 3.019 \\ 0.778 } & \shortstack{ 1.0 \\ 0.258 } & \shortstack{ 1.0 \\ 0.258 } & \shortstack{ 1.0 \\ 0.258 } & \shortstack{ 1.795 \\ 0.463 } \\ 
  \hline
  E & 50 & \shortstack{ 7.255 \\ 0.768 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.0 \\ 0.106 } & \shortstack{ 1.928 \\ 0.204 } \\ 
  \hline
  E & 100 & \shortstack{ 14.051 \\ 0.755 } & \shortstack{ 1.0 \\ 0.054 } & \shortstack{ 1.0 \\ 0.054 } & \shortstack{ 1.0 \\ 0.054 } & \shortstack{ 1.957 \\ 0.105 } \\ 
  \hline
  E & 200 & \shortstack{ 28.026 \\ 0.76 } & \shortstack{ 1.0 \\ 0.027 } & \shortstack{ 1.0 \\ 0.027 } & \shortstack{ 1.0 \\ 0.027 } & \shortstack{ 1.978 \\ 0.054 } \\ 
  \hline
\end{tabular}}

We see that overall, \ii{Nearest Insert} performs rather poorly compared to the other ones.
This is true for all kinds of graphs, as \ii{N.I.} doesn't use any special properties
of metric or Euclidean graphs. It still manages to decrease the total weight of the path
($W$) w.r.t. the original permutation.

The one that performs surprisingly good is the combination of \ii{Swap} followed by
\ii{2-Opt}. In a lot of cases, it even finds the optimal solution. Individually though,
they are not very good.

Right behind those is \ii{Greedy}, which also delivers rather good results. In some cases,
it can also get the optimal solution.

In conclusion, \ii{Swap + 2-Opt} and \ii{Greedy} deliver very good results usually, and
most of the times better than \ii{Nearest Insert}.


\appendix
\section*{APPENDIX}
% \renewcommand{\thesection}{$\Omega$\roman{section}}
\renewcommand{\thesection}{\roman{section}}
\section{Running time of Nearest Insert}
\label{appendix:runtime-ni}

% This section concerns the running time of algorithm \ii{Nearest Insert}.

\subsection{$\argmin$ on line \ref*{init-pi}}

By the concrete properties of our weight functions $w:V\times V\to\mathbb{R}^{+}$
(symmetry and $\forall u\in V\ldotp w(u,u)=0$):
\[ \argmin_{(i,j)\in E} w(i,j) = \argmin_{\substack{(i,j)\in V\times V\\j<i}} w(i,j) \]
So the running time, which depends on the number of lookups (where a lookup of $w(i,j)$
is $\Theta(1)$, because we represent $w$ as a matrix):
\[ \sum_{i=0}^{n-1} \sum_{j=0}^{i-1} \Theta(1) = \Theta(1) \sum_{i=0}^{n-1} i
  = \Theta(1) \cdot \frac{(n-1)(n-1+1)}{2} = \Theta(n^2) \]
\qed

\subsection{Unused nodes set on line \ref*{init-unused}}

Here we iterate over $n$ nodes and check their membership in a list of 2. This means
running time $\Theta(2n) = \Theta(n)$. \qed

\subsection{$\argmin$ on line \ref*{argmin-iu}}

In each iteration of the \bb{while} loop let $k$ be the number of iteration,
starting at $k=0$ just after initialization. Let $\pi_k$ and $U_k$ be the permutation,
and unused nodes set, respectively, after $k^{\mathrm{th}}$ iteration.
Then $|\pi_k| = |\pi_0|+k = k+2$, since at every iteration we
add one node to $\pi$, and we start off with two nodes ($|\pi_0|=2$). In all iterations,
$\pi_k\cup U_k=V$ and $\pi_k\cap U_k=\varnothing$, so $|U_k|=n-|\pi_k|$. A lookup takes
$\Theta(1)$ time. Then running time of $\argmin_{(i,v):\;i\in\{0,...,|\pi|-1\},\;v\in U}
\left\{w\left(\pi[i], v\right)\right\}$ is, in every iteration:

\begin{align*}
  \Theta(|\pi_k||U_k|) & = \Theta\left[ (k+2)(n-(k+2)) \right] \\
                       & = \Theta\left[ (k+2)(n-k-2) \right] \\
                       & = \Theta(kn - k^2 - 2k + 2n - 2k - 4) \\
                       & = \Theta(2n + kn - k^2 - 4k - 4) \\
                       & = \Theta(n + kn - k^2 - k)
\end{align*}

Our $k$ will range over $\{0,...,n-2\}$. If $k=0$ (\bb{base case}):
\begin{align*}
  \Theta(|\pi_0||U_0|) & = \Theta(n + kn - k^2 - k) \\
                       & = \Theta(n + 0 - 0 - 0)
\end{align*}
\begin{equation}
  \label{base-case}
  \therefore \Theta(|\pi_0||U_0|) = \Theta(n)
\end{equation}

Now show that if for arbirary $k\in\{0,...,n-3\}$ it is true thaty
$\Theta(|\pi_k||U_k|) = \Theta(n + kn - k^2 - k) = \Theta(n)$ then for
$k+1$ it holds too.

\begin{align*}
  \Theta(|\pi_{k+1}||U_{k+1}|) & = \Theta(n + (k+1)n - (k+1)^2 - (k+1)) \\
                               & = \Theta(n + kn + n - k^2 - 2k - 1 -k -1) \\
                               & = \Theta(2n + kn - k^2 - 3k - 2) \\
                               & = \Theta(n + kn - k^2 - k) \\
                               & = \Theta(|\pi_k||U_k|) \\
\end{align*}
And now by induction from (\ref*{base-case}), we get that:
\[ \therefore \forall k\in\{0,...,n-2\}\ldotp
  \Theta(|\pi_k||U_k|) = \Theta(n)\]
\qed


\bibliographystyle{abbrv}
\begin{thebibliography}{9}
\bibitem{nilsson}
  Christian Nilsson,
  \textit{Heuristics for the Traveling Salesman Problem},
  Link\"oping University,
  2003.
  Accessible online [27-03-2020]: \url{https://pdfs.semanticscholar.org/7b80/bfc1c5dd4e10ec807c6f56d0f31f8bf86bc6.pdf}
\end{thebibliography}

\end{document}
